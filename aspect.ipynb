{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/amifaraj/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/amifaraj/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/amifaraj/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/amifaraj/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/amifaraj/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/amifaraj/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(<Word index=3;text=staff;lemma=staff;upos=NOUN;xpos=NN;feats=Number=Sing;governor=9;dependency_relation=nsubj>,\n",
       "  'det',\n",
       "  <Word index=1;text=The;lemma=the;upos=DET;xpos=DT;feats=Definite=Def|PronType=Art;governor=3;dependency_relation=det>),\n",
       " (<Word index=3;text=staff;lemma=staff;upos=NOUN;xpos=NN;feats=Number=Sing;governor=9;dependency_relation=nsubj>,\n",
       "  'compound',\n",
       "  <Word index=2;text=hotel;lemma=hotel;upos=NOUN;xpos=NN;feats=Number=Sing;governor=3;dependency_relation=compound>),\n",
       " (<Word index=9;text=friendly;lemma=friendly;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=0;dependency_relation=root>,\n",
       "  'nsubj',\n",
       "  <Word index=3;text=staff;lemma=staff;upos=NOUN;xpos=NN;feats=Number=Sing;governor=9;dependency_relation=nsubj>),\n",
       " (<Word index=5;text=owner;lemma=owner;upos=NOUN;xpos=NN;feats=Number=Sing;governor=3;dependency_relation=conj>,\n",
       "  'cc',\n",
       "  <Word index=4;text=and;lemma=and;upos=CCONJ;xpos=CC;feats=_;governor=5;dependency_relation=cc>),\n",
       " (<Word index=3;text=staff;lemma=staff;upos=NOUN;xpos=NN;feats=Number=Sing;governor=9;dependency_relation=nsubj>,\n",
       "  'conj',\n",
       "  <Word index=5;text=owner;lemma=owner;upos=NOUN;xpos=NN;feats=Number=Sing;governor=3;dependency_relation=conj>),\n",
       " (<Word index=9;text=friendly;lemma=friendly;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=0;dependency_relation=root>,\n",
       "  'cop',\n",
       "  <Word index=6;text=were;lemma=be;upos=AUX;xpos=VBD;feats=Mood=Ind|Tense=Past|VerbForm=Fin;governor=9;dependency_relation=cop>),\n",
       " (<Word index=9;text=friendly;lemma=friendly;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=0;dependency_relation=root>,\n",
       "  'advmod',\n",
       "  <Word index=7;text=not;lemma=not;upos=PART;xpos=RB;feats=_;governor=9;dependency_relation=advmod>),\n",
       " (<Word index=9;text=friendly;lemma=friendly;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=0;dependency_relation=root>,\n",
       "  'advmod',\n",
       "  <Word index=8;text=very;lemma=very;upos=ADV;xpos=RB;feats=_;governor=9;dependency_relation=advmod>),\n",
       " (<Word index=0;text=ROOT>,\n",
       "  'root',\n",
       "  <Word index=9;text=friendly;lemma=friendly;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=0;dependency_relation=root>),\n",
       " (<Word index=9;text=friendly;lemma=friendly;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=0;dependency_relation=root>,\n",
       "  'punct',\n",
       "  <Word index=10;text=.;lemma=.;upos=PUNCT;xpos=.;feats=_;governor=9;dependency_relation=punct>)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "#stanfordnlp.download('en')   # This downloads the English models for the neural pipeline\n",
    "# IMPORTANT: The above line prompts you before downloading, which doesn't work well in a Jupyter notebook.\n",
    "# To avoid a prompt when using notebooks, instead use: >>> stanfordnlp.download('en', force=True)\n",
    "nlp = stanfordnlp.Pipeline()\n",
    "#nlp = stanfordnlp.Pipeline() # This sets up a default neural pipeline in English\n",
    "\n",
    "doc.sentences[0].dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'posTag'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-150cfe647d17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Barack Obama was born in Hawaii.  He was a good person.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'posTag'"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"Barack Obama was born in Hawaii.  He was a good person.\"\n",
    "text.posTag(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sentence' object has no attribute 'parseTree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c78c7037d02e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstanfordnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCoreNLPClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdependency_parse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sentence' object has no attribute 'parseTree'"
     ]
    }
   ],
   "source": [
    "dependency_parse = doc.sentences[0].parseTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StanfordCoreNLP' from 'stanfordnlp' (/home/amifaraj/anaconda3/lib/python3.7/site-packages/stanfordnlp/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a5f82986b488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#from nltk.parse.stanford import StanfordDependencyParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstanfordnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstanfordnlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStanfordCoreNLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpath_to_jar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'stanford-corenlp-full-2018-10-05.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath_to_models_jar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'stanford-english-kbp-corenlp-2018-10-05-models.jar'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'StanfordCoreNLP' from 'stanfordnlp' (/home/amifaraj/anaconda3/lib/python3.7/site-packages/stanfordnlp/__init__.py)"
     ]
    }
   ],
   "source": [
    "#from nltk.parse.stanford import StanfordDependencyParser\n",
    "import stanfordnlp\n",
    "from stanfordnlp import StanfordCoreNLP\n",
    "path_to_jar = 'stanford-corenlp-full-2018-10-05.zip'\n",
    "path_to_models_jar = 'stanford-english-kbp-corenlp-2018-10-05-models.jar'\n",
    "\n",
    "dependency_parser = StanfordCoreNLP(path_to_jar=path_to_jar, path_to_models_jar=path_to_models_jar)\n",
    "\n",
    "result = dependency_parser.raw_parse('I shot an elephant in my sleep')\n",
    "dep = result.next()\n",
    "\n",
    "list(dep.triples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/amifaraj/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('He', '5', 'nsubj')\n",
      "('was', '5', 'cop')\n",
      "('a', '5', 'det')\n",
      "('good', '5', 'amod')\n",
      "('person', '0', 'root')\n",
      "('.', '5', 'punct')\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Barack Obama was born in Hawaii.  He was a good person.\")\n",
    "d = doc.sentences[1].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Token: [('Barack', 'NNP'), ('Obama', 'NNP'), ('was', 'VBD'), ('born', 'VBN'), ('in', 'IN'), ('Hawaii.', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk import RegexpParser\n",
    "text =\"Barack Obama was born in Hawaii.\".split()\n",
    "#print(\"After Split:\",text)\n",
    "tokens_tag = pos_tag(text)\n",
    "print(\"After Token:\",tokens_tag)\n",
    "#patterns= \"\"\"mychunk:{<NN.?>*<VBD.?>*<JJ.?>*<CC>?}\"\"\"\n",
    "#chunker = RegexpParser(patterns)\n",
    "#print(\"After Regex:\",chunker)\n",
    "#output = chunker.parse(tokens_tag)\n",
    "#print(\"After Chunking\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hotel</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>staff,</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>manager</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>owner</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>were</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>not</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>very</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>friendly</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>supportive.</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word POS tag\n",
       "0           The      DT\n",
       "1         hotel      NN\n",
       "2        staff,      NN\n",
       "3       manager      NN\n",
       "4           and      CC\n",
       "5         owner      NN\n",
       "6          were     VBD\n",
       "7           not      RB\n",
       "8          very      RB\n",
       "9      friendly      JJ\n",
       "10          and      CC\n",
       "11  supportive.      NN"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "text = \"The hotel staff, manager and owner were not very friendly and supportive.\"\n",
    "nltk_pos_tagged = pos_tag(text.split())\n",
    "pd.DataFrame(nltk_pos_tagged, columns=['Word', 'POS tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gov</th>\n",
       "      <th>rel</th>\n",
       "      <th>dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;Word index=2;text=consider;lemma=consider;upo...</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>&lt;Word index=1;text=I;lemma=I;upos=PRON;xpos=PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;Word index=0;text=ROOT&gt;</td>\n",
       "      <td>root</td>\n",
       "      <td>&lt;Word index=2;text=consider;lemma=consider;upo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;Word index=5;text=staff;lemma=staff;upos=NOUN...</td>\n",
       "      <td>det</td>\n",
       "      <td>&lt;Word index=3;text=the;lemma=the;upos=DET;xpos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;Word index=5;text=staff;lemma=staff;upos=NOUN...</td>\n",
       "      <td>compound</td>\n",
       "      <td>&lt;Word index=4;text=hotel;lemma=hotel;upos=NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;Word index=2;text=consider;lemma=consider;upo...</td>\n",
       "      <td>obj</td>\n",
       "      <td>&lt;Word index=5;text=staff;lemma=staff;upos=NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;Word index=2;text=consider;lemma=consider;upo...</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>&lt;Word index=6;text=rude;lemma=rude;upos=ADJ;xp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 gov       rel  \\\n",
       "0  <Word index=2;text=consider;lemma=consider;upo...     nsubj   \n",
       "1                           <Word index=0;text=ROOT>      root   \n",
       "2  <Word index=5;text=staff;lemma=staff;upos=NOUN...       det   \n",
       "3  <Word index=5;text=staff;lemma=staff;upos=NOUN...  compound   \n",
       "4  <Word index=2;text=consider;lemma=consider;upo...       obj   \n",
       "5  <Word index=2;text=consider;lemma=consider;upo...     xcomp   \n",
       "\n",
       "                                                 dep  \n",
       "0  <Word index=1;text=I;lemma=I;upos=PRON;xpos=PR...  \n",
       "1  <Word index=2;text=consider;lemma=consider;upo...  \n",
       "2  <Word index=3;text=the;lemma=the;upos=DET;xpos...  \n",
       "3  <Word index=4;text=hotel;lemma=hotel;upos=NOUN...  \n",
       "4  <Word index=5;text=staff;lemma=staff;upos=NOUN...  \n",
       "5  <Word index=6;text=rude;lemma=rude;upos=ADJ;xp...  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import stanfordnlp\n",
    "#nlp = stanfordnlp.Pipeline()\n",
    "#nlp = stanfordnlp.Pipeline() # This sets up a default neural pipeline in English\n",
    "\n",
    "#doc.sentences.dependencies\n",
    "text = 'I consider the hotel staff rude'\n",
    "doc = nlp(text)\n",
    "df = pd.DataFrame(doc.sentences[0].dependencies, columns=['gov', 'rel', 'dep'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['staff', 'manager', 'owner']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nounList=['staff']\n",
    "nounList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(0,len(df)):\n",
    "    if df['rel'][d]=='conj' and df['gov'][d].lemma=='staff':\n",
    "        nounList.append(df['dep'][d].lemma)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<Word index=3;text=staff;lemma=staff;upos=NOUN;xpos=NN;feats=Number=Sing;governor=11;dependency_relation=nsubj>,\n",
       "  'det',\n",
       "  <Word index=1;text=The;lemma=the;upos=DET;xpos=DT;feats=Definite=Def|PronType=Art;governor=3;dependency_relation=det>),\n",
       " (<Word index=3;text=staff;lemma=staff;upos=NOUN;xpos=NN;feats=Number=Sing;governor=11;dependency_relation=nsubj>,\n",
       "  'compound',\n",
       "  <Word index=2;text=hotel;lemma=hotel;upos=NOUN;xpos=NN;feats=Number=Sing;governor=3;dependency_relation=compound>),\n",
       " (<Word index=11;text=friendly;lemma=friendly;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=0;dependency_relation=root>,\n",
       "  'nsubj',\n",
       "  <Word index=3;text=staff;lemma=staff;upos=NOUN;xpos=NN;feats=Number=Sing;governor=11;dependency_relation=nsubj>),\n",
       " (<Word index=5;text=manager;lemma=manager;upos=NOUN;xpos=NN;feats=Number=Sing;governor=3;dependency_relation=conj>,\n",
       "  'punct',\n",
       "  <Word index=4;text=,;lemma=,;upos=PUNCT;xpos=,;feats=_;governor=5;dependency_relation=punct>),\n",
       " (<Word index=3;text=staff;lemma=staff;upos=NOUN;xpos=NN;feats=Number=Sing;governor=11;dependency_relation=nsubj>,\n",
       "  'conj',\n",
       "  <Word index=5;text=manager;lemma=manager;upos=NOUN;xpos=NN;feats=Number=Sing;governor=3;dependency_relation=conj>),\n",
       " (<Word index=7;text=owner;lemma=owner;upos=NOUN;xpos=NN;feats=Number=Sing;governor=3;dependency_relation=conj>,\n",
       "  'cc',\n",
       "  <Word index=6;text=and;lemma=and;upos=CCONJ;xpos=CC;feats=_;governor=7;dependency_relation=cc>),\n",
       " (<Word index=3;text=staff;lemma=staff;upos=NOUN;xpos=NN;feats=Number=Sing;governor=11;dependency_relation=nsubj>,\n",
       "  'conj',\n",
       "  <Word index=7;text=owner;lemma=owner;upos=NOUN;xpos=NN;feats=Number=Sing;governor=3;dependency_relation=conj>),\n",
       " (<Word index=11;text=friendly;lemma=friendly;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=0;dependency_relation=root>,\n",
       "  'cop',\n",
       "  <Word index=8;text=were;lemma=be;upos=AUX;xpos=VBD;feats=Mood=Ind|Tense=Past|VerbForm=Fin;governor=11;dependency_relation=cop>),\n",
       " (<Word index=11;text=friendly;lemma=friendly;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=0;dependency_relation=root>,\n",
       "  'advmod',\n",
       "  <Word index=9;text=not;lemma=not;upos=PART;xpos=RB;feats=_;governor=11;dependency_relation=advmod>),\n",
       " (<Word index=11;text=friendly;lemma=friendly;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=0;dependency_relation=root>,\n",
       "  'advmod',\n",
       "  <Word index=10;text=very;lemma=very;upos=ADV;xpos=RB;feats=_;governor=11;dependency_relation=advmod>),\n",
       " (<Word index=0;text=ROOT>,\n",
       "  'root',\n",
       "  <Word index=11;text=friendly;lemma=friendly;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=0;dependency_relation=root>),\n",
       " (<Word index=13;text=supportive;lemma=supportive;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=11;dependency_relation=conj>,\n",
       "  'cc',\n",
       "  <Word index=12;text=and;lemma=and;upos=CCONJ;xpos=CC;feats=_;governor=13;dependency_relation=cc>),\n",
       " (<Word index=11;text=friendly;lemma=friendly;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=0;dependency_relation=root>,\n",
       "  'conj',\n",
       "  <Word index=13;text=supportive;lemma=supportive;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=11;dependency_relation=conj>),\n",
       " (<Word index=11;text=friendly;lemma=friendly;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=0;dependency_relation=root>,\n",
       "  'punct',\n",
       "  <Word index=14;text=.;lemma=.;upos=PUNCT;xpos=.;feats=_;governor=11;dependency_relation=punct>)]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentences[0].dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det\n",
      "compound\n",
      "nsubj\n",
      "punct\n",
      "conj\n",
      "cc\n",
      "conj\n",
      "cop\n",
      "advmod\n",
      "advmod\n",
      "root\n",
      "cc\n",
      "conj\n",
      "punct\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(doc.sentences[0].dependencies)):\n",
    "    print(doc.sentences[0].dependencies[i][2].dependency_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc.sentences[0].dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gov: NOUN\n",
      "det\n",
      "dep: DET\n",
      "****\n",
      "gov: NOUN\n",
      "compound\n",
      "dep: NOUN\n",
      "****\n",
      "gov: ADJ\n",
      "nsubj\n",
      "dep: NOUN\n",
      "****\n",
      "gov: NOUN\n",
      "punct\n",
      "dep: PUNCT\n",
      "****\n",
      "gov: NOUN\n",
      "conj\n",
      "dep: NOUN\n",
      "****\n",
      "gov: NOUN\n",
      "cc\n",
      "dep: CCONJ\n",
      "****\n",
      "gov: NOUN\n",
      "conj\n",
      "dep: NOUN\n",
      "****\n",
      "gov: ADJ\n",
      "cop\n",
      "dep: AUX\n",
      "****\n",
      "gov: ADJ\n",
      "advmod\n",
      "dep: PART\n",
      "****\n",
      "gov: ADJ\n",
      "advmod\n",
      "dep: ADV\n",
      "****\n",
      "gov: None\n",
      "root\n",
      "dep: ADJ\n",
      "****\n",
      "gov: ADJ\n",
      "cc\n",
      "dep: CCONJ\n",
      "****\n",
      "gov: ADJ\n",
      "conj\n",
      "dep: ADJ\n",
      "****\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(doc.sentences[0].dependencies)-1):\n",
    "    print(\"gov: \"+ str(doc.sentences[0].dependencies[i][0].upos))\n",
    "    print(doc.sentences[0].dependencies[i][1]) \n",
    "    print(\"dep: \"+ doc.sentences[0].dependencies[i][2].upos)\n",
    "    print(\"****\")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel\n",
      "det\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "print(doc.sentences[0].dependencies[0][0].lemma)\n",
    "print(doc.sentences[0].dependencies[0][1])\n",
    "print(doc.sentences[0].dependencies[0][2].lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Regex: chunk.RegexpParser with 1 stages:\n",
      "RegexpChunkParser with 1 rules:\n",
      "       <ChunkRule: '<nsubj.?>*<VBD.?>*<JJ.?>*<CC>?'>\n"
     ]
    }
   ],
   "source": [
    "patterns= \"\"\"mychunk:{<nsubj.?>*<VBD.?>*<JJ.?>*<CC>?}\"\"\"\n",
    "chunker = RegexpParser(patterns)\n",
    "print(\"After Regex:\",chunker)\n",
    "#output = chunker.parse(tokens_tag)\n",
    "#print(\"After Chunking\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The hotel staff and owner were not very friendly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amifaraj/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: The StanfordDependencyParser will be deprecated\n",
      "Please use \u001b[91mnltk.parse.corenlp.StanforCoreNLPDependencyParser\u001b[0m instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Tree('friendly', [Tree('staff', ['The', 'hotel', 'and', 'owner']), 'were', 'not', 'very'])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "sdp = StanfordDependencyParser(path_to_jar='stanford/stanford-corenlp-3.9.2.jar',path_to_models_jar='stanford/stanford-corenlp-3.9.2-models.jar')    \n",
    "\n",
    "result = list(sdp.raw_parse(text))  \n",
    "\n",
    "# print the dependency tree\n",
    "dep_tree = [parse.tree() for parse in result][0]\n",
    "dep_tree\n",
    "\n",
    "# visualize raw dependency tree\n",
    "#from IPython.display import display\n",
    "#display(dep_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. extractDependencies(Sentence)\n",
    "2. getNounSiblings(d.dep)\n",
    "3. getAdjectiveSiblings(d.gov)\n",
    "4. isAffirmative(?)\n",
    "5. isAdjective\n",
    "6. isVerb\n",
    "7. isNoun()\n",
    "8. isPronoun()\n",
    "9. getAdjectiveModifiers()\n",
    "10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDependencies(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    dependency = doc.sentences[0].dependencies\n",
    "    depTable = pd.DataFrame(dependency, columns=['gov', 'rel', 'dep'])\n",
    "    return depTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNounSibling(depTable, Col, row):\n",
    "    noun = depTable[Col][row].lemma\n",
    "    nounList=[noun]\n",
    "    for index in range(0,len(depTable)):\n",
    "        if depTable['rel'][index] =='conj' and depTable['gov'][index].lemma == noun:\n",
    "            nounList.append(depTable['dep'][index].lemma)\n",
    "    return nounList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAdjectiveSibling(depTable, Col, row):\n",
    "    adj = depTable[Col][row].lemma\n",
    "    adjList=[adj]\n",
    "    for index in range(0,len(depTable)):\n",
    "        if depTable['rel'][index] =='conj' and depTable['gov'][index].lemma == adj:\n",
    "            adjList.append(depTable['dep'][index].lemma)\n",
    "    return adjList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAdjectiveModifiers(depTable, Col, row):\n",
    "    adj = depTable[Col][row].lemma\n",
    "    adjmod=[]\n",
    "    for index in range(0,len(depTable)):\n",
    "        if depTable['rel'][index] =='advmod' and depTable['gov'][index].lemma == adj:\n",
    "            adjmod.append(depTable['dep'][index].lemma)\n",
    "    return adjmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNoun(depTable, Col, row):\n",
    "    POS = depTable[Col][row].upos\n",
    "    if POS=='NOUN':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isAdjective(depTable, Col, row):\n",
    "    POS = depTable[Col][row].upos\n",
    "    if POS=='ADJ':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isVerb(depTable, Col, row):\n",
    "    POS = depTable[Col][row].xpos\n",
    "    if 'VB' in POS:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isAderb(depTable, Col, row):\n",
    "    POS = depTable[Col][row].xpos\n",
    "    if 'RB' in POS:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/amifaraj/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/amifaraj/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/amifaraj/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/amifaraj/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/amifaraj/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/amifaraj/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "nlp = stanfordnlp.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gov</th>\n",
       "      <th>rel</th>\n",
       "      <th>dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;Word index=4;text=think;lemma=think;upos=VERB...</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>&lt;Word index=1;text=I;lemma=I;upos=PRON;xpos=PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;Word index=4;text=think;lemma=think;upos=VERB...</td>\n",
       "      <td>aux</td>\n",
       "      <td>&lt;Word index=2;text=do;lemma=do;upos=AUX;xpos=V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;Word index=4;text=think;lemma=think;upos=VERB...</td>\n",
       "      <td>advmod</td>\n",
       "      <td>&lt;Word index=3;text=not;lemma=not;upos=PART;xpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;Word index=0;text=ROOT&gt;</td>\n",
       "      <td>root</td>\n",
       "      <td>&lt;Word index=4;text=think;lemma=think;upos=VERB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;Word index=7;text=staff;lemma=staff;upos=NOUN...</td>\n",
       "      <td>det</td>\n",
       "      <td>&lt;Word index=5;text=the;lemma=the;upos=DET;xpos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;Word index=7;text=staff;lemma=staff;upos=NOUN...</td>\n",
       "      <td>compound</td>\n",
       "      <td>&lt;Word index=6;text=hotel;lemma=hotel;upos=NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;Word index=9;text=friendly;lemma=friendly;upo...</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>&lt;Word index=7;text=staff;lemma=staff;upos=NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;Word index=9;text=friendly;lemma=friendly;upo...</td>\n",
       "      <td>cop</td>\n",
       "      <td>&lt;Word index=8;text=were;lemma=be;upos=AUX;xpos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;Word index=4;text=think;lemma=think;upos=VERB...</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>&lt;Word index=9;text=friendly;lemma=friendly;upo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 gov       rel  \\\n",
       "0  <Word index=4;text=think;lemma=think;upos=VERB...     nsubj   \n",
       "1  <Word index=4;text=think;lemma=think;upos=VERB...       aux   \n",
       "2  <Word index=4;text=think;lemma=think;upos=VERB...    advmod   \n",
       "3                           <Word index=0;text=ROOT>      root   \n",
       "4  <Word index=7;text=staff;lemma=staff;upos=NOUN...       det   \n",
       "5  <Word index=7;text=staff;lemma=staff;upos=NOUN...  compound   \n",
       "6  <Word index=9;text=friendly;lemma=friendly;upo...     nsubj   \n",
       "7  <Word index=9;text=friendly;lemma=friendly;upo...       cop   \n",
       "8  <Word index=4;text=think;lemma=think;upos=VERB...     ccomp   \n",
       "\n",
       "                                                 dep  \n",
       "0  <Word index=1;text=I;lemma=I;upos=PRON;xpos=PR...  \n",
       "1  <Word index=2;text=do;lemma=do;upos=AUX;xpos=V...  \n",
       "2  <Word index=3;text=not;lemma=not;upos=PART;xpo...  \n",
       "3  <Word index=4;text=think;lemma=think;upos=VERB...  \n",
       "4  <Word index=5;text=the;lemma=the;upos=DET;xpos...  \n",
       "5  <Word index=6;text=hotel;lemma=hotel;upos=NOUN...  \n",
       "6  <Word index=7;text=staff;lemma=staff;upos=NOUN...  \n",
       "7  <Word index=8;text=were;lemma=be;upos=AUX;xpos...  \n",
       "8  <Word index=9;text=friendly;lemma=friendly;upo...  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'I do not think the hotel staff were friendly'\n",
    "df = extractDependencies(text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
